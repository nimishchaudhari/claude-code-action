name: Claude PR Assistant (Multi-LLM)

on:
  issue_comment:
    types: [created]
  pull_request_review_comment:
    types: [created]
  issues:
    types: [opened, assigned]
  pull_request_review:
    types: [submitted]

jobs:
  claude-code-action:
    if: |
      (github.event_name == 'issue_comment' && contains(github.event.comment.body, '@claude')) ||
      (github.event_name == 'pull_request_review_comment' && contains(github.event.comment.body, '@claude')) ||
      (github.event_name == 'pull_request_review' && contains(github.event.review.body, '@claude')) ||
      (github.event_name == 'issues' && contains(github.event.issue.body, '@claude'))
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
      issues: read
      id-token: write
    services:
      claude-proxy:
        image: python:3.11-slim
        ports:
          - 8082:8082
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          PREFERRED_PROVIDER: ${{ vars.PREFERRED_PROVIDER || 'openai' }}
          BIG_MODEL: ${{ vars.BIG_MODEL || 'gpt-4' }}
          SMALL_MODEL: ${{ vars.SMALL_MODEL || 'gpt-4o-mini' }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup proxy server
        run: |
          # Install uv
          curl -LsSf https://astral.sh/uv/install.sh | sh
          export PATH="$HOME/.cargo/bin:$PATH"
          
          # Clone and setup proxy server in background
          git clone https://github.com/1rgs/claude-code-openai.git proxy-server
          cd proxy-server
          
          # Create .env file
          cat > .env << EOF
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY=${{ secrets.GEMINI_API_KEY }}
          PREFERRED_PROVIDER=${{ vars.PREFERRED_PROVIDER || 'openai' }}
          BIG_MODEL=${{ vars.BIG_MODEL || 'gpt-4' }}
          SMALL_MODEL=${{ vars.SMALL_MODEL || 'gpt-4o-mini' }}
          EOF
          
          # Start proxy server in background
          uv run uvicorn server:app --host 0.0.0.0 --port 8082 &
          
          # Wait for server to be ready
          sleep 10
          
          # Test proxy server
          curl -f http://localhost:8082/health || (echo "Proxy server failed to start" && exit 1)
        
      - name: Run Claude PR Action
        uses: anthropics/claude-code-action@beta
        with:
          # Route through proxy server instead of direct Anthropic API
          anthropic_api_key: dummy-key-proxy-handles-auth
          anthropic_base_url: http://localhost:8082
          timeout_minutes: "60"
        env:
          # Pass through environment variables for the action
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}